{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import qgrid\n",
    "import pandas_profiling\n",
    "import csv # Savng CSV file\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Reading tables of interests\n",
    "file = \"/Users/nazlirafei/Library/CloudStorage/\"\n",
    "\n",
    "df_abilities = pd.read_excel(file + \"db_26_2_excel/Abilities.xlsx\")\n",
    "df_skills = pd.read_excel(file + \"db_26_2_excel/Skills.xlsx\")\n",
    "df_WorkAct = pd.read_excel(file + \"db_26_2_excel/Work Activities.xlsx\")\n",
    "df_Interests = pd.read_excel(file + \"db_26_2_excel/Interests.xlsx\")\n",
    "df_Workstyle = pd.read_excel(file + \"db_26_2_excel/Work Styles.xlsx\")\n",
    "\n",
    "\n",
    "df_occupations = pd.read_excel(file + \"db_26_2_excel/Occupation Data.xlsx\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the tables of interest, we need to filter for \"LV\" ,a nd in table of Workstyle which we don't have \"LV\" we chose \"IM\" as scale ID. Then columns of interests are chosen and for the reason explained in pdf in labeling section, first four characters of Element ID are cosen for all datasets, then we group by 'O*NET-SOC Code','Title','Element ID' columns and aggregate the data value with mean. Then I droped NA in rows with all NA, make a pivot table to have Element Ids as columns and data values as row. And finally merged all tables from our four different tables of interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [df_abilities, df_skills, df_WorkAct, df_Workstyle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting \"Element Names\" which describe Analytical occupation\n",
    "selected_elements=['O*NET-SOC Code','Title','1.A.1.b','1.C.7.a','1.C.7.b','2.A.2.a','2.A.2.b','2.B.2.i','4.A.2.a','4.A.2.b'] \n",
    "\n",
    "# filter go scale ID for differnet tables, those which has \"LV\",\n",
    "# \"LV\" was chosen and for others either \"IM\" \n",
    "for i in range(0,4):\n",
    "    if i == 3:\n",
    "        df[i] = df[i][df[i]['Scale ID'] == 'IM']\n",
    "    else: \n",
    "        df[i] = df[i][df[i]['Scale ID'] == 'LV']\n",
    "    #Picking columns of interests\n",
    "    df[i] = df[i][[\"O*NET-SOC Code\", \"Title\", \"Element ID\", \"Data Value\"]]\n",
    "\n",
    "    #Taking out just first four digits of element ID of all these data.\n",
    "    df[i]['Element ID'] = df[i]['Element ID'].map(lambda x:x[:7])\n",
    "\n",
    "    # Group by 'O*NET-SOC Code','Title','Element ID', to get the mean of values for Data Value for each observation\n",
    "    df[i] = df[i].groupby(['O*NET-SOC Code','Title','Element ID']).agg({'Data Value': 'mean'}).reset_index().rename(columns={'Data Value':'Avg Data Value'})\n",
    "    \n",
    "    #Round number for Avg Data Value to two decimal\n",
    "    df[i]['Avg Data Value']=df[i]['Avg Data Value'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # MAke Pivot table to have data value for each element\n",
    "    df[i]=df[i].pivot_table(index=['O*NET-SOC Code', \"Title\"],columns='Element ID',values='Avg Data Value').reset_index()\n",
    "    if i == 2:\n",
    "        #df_WorkAct had just one column and so I could use drop NA\n",
    "        df[i] = df[i][df[i].columns.intersection(selected_elements)].dropna()\n",
    "    else: \n",
    "        # Drop rows having only missing values\n",
    "        df[i] = df[i][df[i].columns.intersection(selected_elements)].dropna(how='all')\n",
    "\n",
    "\n",
    "df_merged=df[0].merge(df[1],on=(\"O*NET-SOC Code\",\"Title\"),how='left'\n",
    "                            ).merge(df[2],on=(\"O*NET-SOC Code\",\"Title\"),how='left'\n",
    "                                   ).merge(df[3],on=(\"O*NET-SOC Code\",\"Title\"),how='left').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>1.A.1.b</th>\n",
       "      <th>2.A.2.a</th>\n",
       "      <th>2.A.2.b</th>\n",
       "      <th>2.B.2.i</th>\n",
       "      <th>4.A.2.a</th>\n",
       "      <th>4.A.2.b</th>\n",
       "      <th>1.C.7.a</th>\n",
       "      <th>1.C.7.b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.28</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.03</td>\n",
       "      <td>Chief Sustainability Officers</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1021.00</td>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>3.47</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-2011.00</td>\n",
       "      <td>Advertising and Promotions Managers</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.47</td>\n",
       "      <td>4.49</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-2021.00</td>\n",
       "      <td>Marketing Managers</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.51</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>53-7071.00</td>\n",
       "      <td>Gas Compressor and Gas Pumping Station Operators</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.44</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>53-7072.00</td>\n",
       "      <td>Pump Operators, Except Wellhead Pumpers</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.46</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>53-7073.00</td>\n",
       "      <td>Wellhead Pumpers</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.49</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>53-7081.00</td>\n",
       "      <td>Refuse and Recyclable Material Collectors</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.52</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    O*NET-SOC Code                                             Title  1.A.1.b  \\\n",
       "0       11-1011.00                                  Chief Executives     4.57   \n",
       "1       11-1011.03                     Chief Sustainability Officers     4.05   \n",
       "2       11-1021.00                   General and Operations Managers     3.47   \n",
       "3       11-2011.00               Advertising and Promotions Managers     4.00   \n",
       "4       11-2021.00                                Marketing Managers     3.93   \n",
       "..             ...                                               ...      ...   \n",
       "868     53-7071.00  Gas Compressor and Gas Pumping Station Operators     2.86   \n",
       "869     53-7072.00           Pump Operators, Except Wellhead Pumpers     2.80   \n",
       "870     53-7073.00                                  Wellhead Pumpers     2.70   \n",
       "871     53-7081.00         Refuse and Recyclable Material Collectors     2.30   \n",
       "872     53-7121.00                 Tank Car, Truck, and Ship Loaders     2.68   \n",
       "\n",
       "     2.A.2.a  2.A.2.b  2.B.2.i  4.A.2.a  4.A.2.b  1.C.7.a  1.C.7.b  \n",
       "0       4.75     4.75     5.00     5.37     5.28     4.27     4.45  \n",
       "1       4.12     3.88     4.12     4.58     5.43     4.48     4.52  \n",
       "2       4.00     3.62     3.75     4.07     4.32     3.65     4.03  \n",
       "3       4.12     4.12     3.88     3.47     4.49     3.99     3.88  \n",
       "4       4.25     4.12     3.88     3.51     4.65     4.15     4.00  \n",
       "..       ...      ...      ...      ...      ...      ...      ...  \n",
       "868     3.00     2.38     3.00     4.30     3.91     3.44     4.09  \n",
       "869     3.12     2.88     2.88     3.94     4.18     2.46     3.09  \n",
       "870     3.00     2.12     2.88     3.74     3.60     3.49     3.71  \n",
       "871     3.00     2.00     2.12     2.17     2.52     3.56     3.37  \n",
       "872     2.88     2.75     2.88     4.25     4.01     3.22     3.53  \n",
       "\n",
       "[873 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.DataFrame(df_merged, columns=['O*NET-SOC Code', 'Title', '1.A.1.b', '2.A.2.a', '2.A.2.b', '2.B.2.i',\n",
    "       '4.A.2.a', '4.A.2.b', '1.C.7.a', '1.C.7.b'])\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing element IDs with Element names in order to make it easier to read and underestand\n",
    "df_temp.rename(columns = {'1.A.1.b' : 'Idea Generation and Reasoning Abilities', '1.C.7.a' : 'Innovation',\n",
    " '1.C.7.b' : 'Analytical Thinking' , '2.A.2.a' : 'Critical Thinking', '2.A.2.b' : 'Active Learning',\n",
    "  '2.B.2.i' : 'Complex Problem Solving', '4.A.2.a' : 'Information and Data Processing','4.A.2.b':'Reasoning and Decision Making'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our preprocessed data , let's save it to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv('df_Processed.csv', header=True, na_rep='NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to label subset of our data, we selected 150 samples randomly using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tobe_labeled=df_temp.sample(n=150, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to label the data, I attached current table with df_occupations so I can have the description of each job, and decde if its Analytical or not based on the descrition of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tobe_labeled=df_tobe_labeled.merge(df_occupations,on=(\"Title\",\"O*NET-SOC Code\"),\n",
    "                                      how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing data so the description and title are next to each other,\n",
    "#  adding a colum to define if a job is Analytical or not\n",
    "# followed by our features of interest\n",
    "\n",
    "df_tobe_labeled=df_tobe_labeled.reindex(columns=[\"O*NET-SOC Code\", \"Title\",\"Analytical\",\"Description\", 'Idea Generation and Reasoning Abilities',\n",
    "       'Critical Thinking', 'Active Learning', 'Complex Problem Solving',\n",
    "       'Information and Data Processing', 'Reasoning and Decision Making',\n",
    "       'Innovation', 'Analytical Thinking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our sampled data into csv to evaluate and label easier \n",
    "df_tobe_labeled.to_csv('df_tobe_labeled.csv', header=True, na_rep='NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read New Labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were labeled through eyeballing in excel file, and now we read the dataset which is saved as df_labeled.scv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled=pd.read_csv(\"df_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping extra column named 'Unnamed: 0'\n",
    "df_labeled=df_labeled.drop('Unnamed: 0',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of classes in our Analytical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    104\n",
       "1     46\n",
       "Name: Analytical, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled['Analytical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies Projects/PRoject-rev06.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies%20Projects/PRoject-rev06.ipynb#ch0000031?line=0'>1</a>\u001b[0m \u001b[39m#ploting the distribution with different color to each class.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies%20Projects/PRoject-rev06.ipynb#ch0000031?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies%20Projects/PRoject-rev06.ipynb#ch0000031?line=3'>4</a>\u001b[0m sns\u001b[39m.\u001b[39mcountplot(x\u001b[39m=\u001b[39my,data\u001b[39m=\u001b[39mdf_labeled,hue\u001b[39m=\u001b[39my)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ploting the distribution with different color to each class.\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x=y,data=df_labeled,hue=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see our data is imbalanced and we have to take this into consideration while modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to do a train test split, and train our model!\n",
    "\n",
    "Use sklearn to split your data into a training set and a testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O*NET-SOC Code                             0\n",
       "Title                                      0\n",
       "Analytical                                 0\n",
       "Description                                0\n",
       "Idea Generation and Reasoning Abilities    0\n",
       "Critical Thinking                          0\n",
       "Active Learning                            0\n",
       "Complex Problem Solving                    0\n",
       "Information and Data Processing            0\n",
       "Reasoning and Decision Making              0\n",
       "Innovation                                 0\n",
       "Analytical Thinking                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df_labeled.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 features selected to perform models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to features (x) , and target (y)\n",
    "X = df_labeled[['Idea Generation and Reasoning Abilities', 'Critical Thinking',\n",
    "       'Active Learning', 'Complex Problem Solving',\n",
    "       'Information and Data Processing', 'Reasoning and Decision Making',\n",
    "       'Innovation', 'Analytical Thinking']]\n",
    "y = df_labeled[\"Analytical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test (!!! in models we will oversample/undersample when it is needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and matrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve, roc_auc_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE have imbalanced data set one way to deal with that is to do upscaling or downscaling however here in logistic regression we can use class-weight to deal with this as well, which in a way the algorithm is punished for any wrong prediction of that class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First building a logistic regression with default weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7555555555555555\n",
      "Confusion Matrix: \n",
      "[[26  4]\n",
      " [ 7  8]]\n",
      "Area Under Curve: 0.7\n",
      "Recall score: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "lg1 = LogisticRegression(random_state=42, class_weight=None)\n",
    "# fit it\n",
    "lg1.fit(X_train,y_train)\n",
    "# test\n",
    "y_pred_lg1 = lg1.predict(X_test)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred_lg1)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_lg1)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_lg1)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred_lg1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        30\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.76        45\n",
      "   macro avg       0.73      0.70      0.71        45\n",
      "weighted avg       0.75      0.76      0.75        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_lg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For minority class, above model is able to predict 8 correct out of 15 samples. For majority class, model got four prediction wrong. Model is not doing a good job in predicting minority class. Nonetheless, with these default weights performance values, we got benchmark to measure subsequent model modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case be unbalanced label distribution, the best practice for weights is to use the inverse of the label distribution. In our set, label distribution is 46:104  so we can specify weights as inverse of label distribution. For majority class, will use weight of 1 and for minority class, will use weight of 2.26. So the penalty of wrong prediction of minority class would be 2.26 times more severe than wrong prediction of majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7333333333333333\n",
      "Confusion Matrix: \n",
      "[[23  7]\n",
      " [ 5 10]]\n",
      "Area Under Curve: 0.7166666666666666\n",
      "Recall score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# define class weights\n",
    "w = {0:1, 1:2.26}\n",
    "# define model\n",
    "lg2 = LogisticRegression(random_state=42, class_weight=w)\n",
    "# fit it\n",
    "lg2.fit(X_train,y_train)\n",
    "# test\n",
    "y_pred_lg2 = lg2.predict(X_test)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred_lg2)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_lg2)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_lg2)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred_lg2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With weighted-LG, Area-Under-Curve (AUC) increased drastically from 0.7 to 0.72. Recall score imporved from 0.53 to 0.66. Correct predictions for minority label increased as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, ROC-AUC score is the evaluation metric here, so this score would be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weight hyperparameter\n",
    "w = [{0:1,1:5},{0:1,1:3}, {0:1,1:2}, \n",
    "     {0:1,1:1.5}, {0:1,1:4},  \n",
    "     {0:0.01,1:1.0}, {0:0.01,1:10}, {0:0.01,1:100}, \n",
    "     {0:0.001,1:1.0}, {0:0.005,1:1.0}, {0:1.0,1:1.0}, \n",
    "     {0:1.0,1:0.1}, {0:10,1:0.1}, {0:100,1:0.1}, \n",
    "     {0:10,1:0.01}, {0:1.0,1:0.01}, {0:1.0,1:0.001}, {0:1.0,1:0.005}, \n",
    "     {0:1.0,1:10}, {0:1.0,1:99}, {0:1.0,1:100}, {0:1.0,1:150}, \n",
    "     {0:1.0,1:200}, {0:1.0,1:300},{0:1.0,1:400},{0:1.0,1:500}, \n",
    "     {0:1.0,1:1000}, {0:10,1:1000},{0:100,1:1000} ]\n",
    "hyperparam_grid = {\"class_weight\": w }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9247989417989417 with param: {'class_weight': {0: 1, 1: 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "lg3 = LogisticRegression(random_state=13)\n",
    "# define evaluation procedure\n",
    "grid = GridSearchCV(lg3,hyperparam_grid,scoring=\"roc_auc\", cv=5, n_jobs=-1, refit=True,verbose=2)\n",
    "grid.fit(X,y)\n",
    "print(f'Best score: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using above weight values, lets build logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7777777777777778\n",
      "Confusion Matrix: \n",
      "[[22  8]\n",
      " [ 2 13]]\n",
      "Area Under Curve: 0.8\n",
      "Recall score: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "lg4 = LogisticRegression(random_state=42, class_weight= {0: 1, 1: 5})\n",
    "# fit it\n",
    "lg4.fit(X_train,y_train)\n",
    "# test\n",
    "y_pred_lg4 = lg4.predict(X_test)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred_lg4)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred_lg4)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_pred_lg4)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_pred_lg4)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new weights, we got slight improvement in AUC (from 0.716 to 0.8) and recall score (from 0.666 to 0.86). From confusion matrix, it can be seen that model is doing a good job in predicting minority class. Though we got slight wrong prediction for majority label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.92\n"
     ]
    }
   ],
   "source": [
    "scores_lg4 = cross_val_score(lg4, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean_lg4=round(np.mean(scores_lg4),2)\n",
    "print('Mean AUC:',mean_lg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC: 0.92\n"
     ]
    }
   ],
   "source": [
    "scores_lg1 = cross_val_score(lg1, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean_lg1=round(np.mean(scores_lg1),2)\n",
    "print('Mean AUC:',mean_lg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have imbalanced data set accuracy is not a good measure of performance, and evaluation metrics like ROC-AUC curve are a good indicator of classifier performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        30\n",
      "           1       0.62      0.87      0.72        15\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.77      0.80      0.77        45\n",
      "weighted avg       0.82      0.78      0.78        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_lg4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since our data are inbalanced we have to over sample or undersample our data in different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Over sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 104, 1: 104})\n"
     ]
    }
   ],
   "source": [
    "# instantiating the random over sampler \n",
    "ros = RandomOverSampler()\n",
    "# resampling X, y\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "# new class distribution \n",
    "print(Counter(y_ros))\n",
    "\n",
    "X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 46, 1: 46})\n"
     ]
    }
   ],
   "source": [
    "# instantiating the random undersampler\n",
    "rus = RandomUnderSampler() \n",
    "# resampling X, y\n",
    "X_rus, y_rus = rus.fit_resample(X, y)\n",
    "# new class distribution\n",
    "print(Counter(y_rus))\n",
    "\n",
    "X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At different locations xᵢ and xⱼ, the random variables f(xᵢ) and f(xⱼ) are correlated;\n",
    "\n",
    "we can interpret a random process as an infinite collection of correlated random variables.\n",
    "\n",
    "GP uses Gaussian distribution (or normal distribution) to characterize the random process.\n",
    "\n",
    "the correlation function, also known as the kernel function. \n",
    "\n",
    "a kernel function measures the “similarities” between two different predictions\n",
    "\n",
    "Common kernel functions include the cubic kernel, exponential kernel, Gaussian kernel, and Matérn kernel. This article will use the Gaussian kernel, which is one of the most popular choices.\n",
    "\n",
    "The same reasoning also applies to multiple-feature settings: if the θ value of the kth feature is rather low, then the underlying function would yield similar output values when moving along the kth dimension. Since the output is not so sensitive to the kth feature, we may conclude that the kth feature is not that important when making the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and kernels\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPC = GaussianProcessClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_GPC = {'kernel': [RBF(), DotProduct(),Matern(),\n",
    "                  RationalQuadratic(), WhiteKernel()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_GPC  = GridSearchCV(GPC ,param_grid_GPC ,scoring=\"roc_auc\",\n",
    "                                cv = 5, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  25 | elapsed:    0.1s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9314285714285713 with param: {'kernel': RBF(length_scale=1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "#the best parameters from fitting the random search\n",
    "grid_search_GPC.fit(X_train, y_train)\n",
    "print(f'Best score: {grid_search_GPC.best_score_} with param: {grid_search_GPC.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model on the Optimized GPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7777777777777778\n",
      "Confusion Matrix: \n",
      "[[27  3]\n",
      " [ 7  8]]\n",
      "Area Under Curve: 0.7166666666666666\n",
      "Recall score: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "GPC2 = GaussianProcessClassifier(RBF())\n",
    "# fit it\n",
    "GPC2.fit(X_train,y_train)\n",
    "# test\n",
    "predictions_GPC = GPC2.predict(X_test)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,predictions_GPC)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, predictions_GPC)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, predictions_GPC)}')\n",
    "print(f'Recall score: {recall_score(y_test,predictions_GPC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        30\n",
      "           1       0.73      0.53      0.62        15\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.76      0.72      0.73        45\n",
      "weighted avg       0.77      0.78      0.77        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_GPC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(GPC2, X, y, cv=5, scoring='roc_auc')\n",
    "scores.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies Projects/PRoject-rev06.ipynb Cell 82'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies%20Projects/PRoject-rev06.ipynb#ch0000076?line=0'>1</a>\u001b[0m mean\u001b[39m=\u001b[39m\u001b[39mround\u001b[39m(mean(scores),\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nazlirafei/Library/CloudStorage/OneDrive-NortheasternUniversity/Job/Projects/Companies%20Projects/PRoject-rev06.ipynb#ch0000076?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMean Accuracy:\u001b[39m\u001b[39m'\u001b[39m,mean)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "mean=round(mean(scores),2)\n",
    "print('Mean Accuracy:',mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over samplng and undersampling our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 104, 1: 46})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating a new optimization Gridsearch cv for our new set of dataset after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPC_OS = GaussianProcessClassifier()\n",
    "param_grid_GPC_OS = {'kernel': [RBF(), DotProduct(),Matern(),\n",
    "                  RationalQuadratic(), WhiteKernel()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_GPC_OS  = GridSearchCV(GPC_OS ,param_grid_GPC_OS ,scoring=\"roc_auc\",\n",
    "                                cv = 5, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  25 | elapsed:    0.2s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9199999999999999 with param: {'kernel': DotProduct(sigma_0=1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "#the best parameters from fitting the random search\n",
    "grid_search_GPC_OS.fit(X_train_ros, y_train_ros)\n",
    "print(f'Best score: {grid_search_GPC_OS.best_score_} with param: {grid_search_GPC_OS.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8095238095238095\n",
      "Confusion Matrix: \n",
      "[[25  5]\n",
      " [ 7 26]]\n",
      "Area Under Curve: 0.8106060606060606\n",
      "Recall score: 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "GPC4 = GaussianProcessClassifier(DotProduct(sigma_0=1))\n",
    "# fit it\n",
    "GPC4.fit(X_train_ros,y_train_ros)\n",
    "# test\n",
    "predictions_GPC = GPC4.predict(X_test_ros)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test_ros,predictions_GPC)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test_ros, predictions_GPC)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test_ros, predictions_GPC)}')\n",
    "print(f'Recall score: {recall_score(y_test_ros,predictions_GPC)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPC_US = GaussianProcessClassifier()\n",
    "param_grid_GPC_US = {'kernel': [RBF(), DotProduct(),Matern(),\n",
    "                  RationalQuadratic(), WhiteKernel()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_GPC_US  = GridSearchCV(GPC_US ,param_grid_GPC_US ,scoring=\"roc_auc\",\n",
    "                                cv = 5, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score: 0.9199999999999999 with param: {'kernel': DotProduct(sigma_0=1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  25 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#the best parameters from fitting the random search\n",
    "grid_search_GPC_US.fit(X_train_rus, y_train_rus)\n",
    "print(f'Best score: {grid_search_GPC_OS.best_score_} with param: {grid_search_GPC_OS.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8214285714285714\n",
      "Confusion Matrix: \n",
      "[[12  4]\n",
      " [ 1 11]]\n",
      "Area Under Curve: 0.8333333333333334\n",
      "Recall score: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "GPC5 = GaussianProcessClassifier(DotProduct(sigma_0=1))\n",
    "# fit it\n",
    "GPC5.fit(X_train_rus,y_train_rus)\n",
    "# test\n",
    "predictions_GPC5 = GPC5.predict(X_test_rus)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test_rus,predictions_GPC5)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test_rus, predictions_GPC5)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test_rus, predictions_GPC5)}')\n",
    "print(f'Recall score: {recall_score(y_test_rus,predictions_GPC5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here undersampling shows a better result, in our model with AUC increasing (from 0.793 to 0.0.812), and Reacll score increasing (from  0.787 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.83        16\n",
      "           1       0.73      0.92      0.81        12\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.83      0.83      0.82        28\n",
      "weighted avg       0.84      0.82      0.82        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rus,predictions_GPC5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(GPC5, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean=round(np.mean(scores),2)\n",
    "print('Mean Accuracy:',mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.92\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score on Test set</th>\n",
       "      <th>Area Under Curve</th>\n",
       "      <th>Recall score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted Logistic Regression</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy Score on Test set   \\\n",
       "0           Logistic Regression                     0.755556   \n",
       "1  Weighted Logistic Regression                     0.777778   \n",
       "2   Gaussian Process Classifier                     0.785714   \n",
       "\n",
       "   Area Under Curve  Recall score  \n",
       "0            0.7000      0.533333  \n",
       "1            0.8000      0.866667  \n",
       "2            0.8125      1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Model': [\"Logistic Regression\",\"Weighted Logistic Regression\", \"Gaussian Process Classifier\"],\n",
    " 'Accuracy Score on Test set ': [(accuracy_score(y_test,y_pred_lg1)),(accuracy_score(y_test,y_pred_lg4)),(accuracy_score(y_test_rus,predictions_GPC5)) ], \n",
    " 'Area Under Curve':[(roc_auc_score(y_test, y_pred_lg1)),(roc_auc_score(y_test, y_pred_lg4)),(roc_auc_score(y_test_rus, predictions_GPC5))],\n",
    " 'Recall score':[(recall_score(y_test,y_pred_lg1)),(recall_score(y_test,y_pred_lg4)),(recall_score(y_test_rus,predictions_GPC5))]}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Accuracy Score: {accuracy_score(y_test_rus,predictions_GPC5)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test_rus, predictions_GPC5)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test_rus, predictions_GPC5)}')\n",
    "print(f'Recall score: {recall_score(y_test_rus,predictions_GPC5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        30\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.76        45\n",
      "   macro avg       0.73      0.70      0.71        45\n",
      "weighted avg       0.75      0.76      0.75        45\n",
      "\n",
      "Weighted Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        30\n",
      "           1       0.62      0.87      0.72        15\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.77      0.80      0.77        45\n",
      "weighted avg       0.82      0.78      0.78        45\n",
      "\n",
      "Gaussian Process Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77        16\n",
      "           1       0.67      1.00      0.80        12\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.83      0.81      0.78        28\n",
      "weighted avg       0.86      0.79      0.78        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(classification_report(y_test,y_pred_lg1))\n",
    "print(\"Weighted Logistic Regression\")\n",
    "print(classification_report(y_test,y_pred_lg4))\n",
    "print(\"Gaussian Process Classifier\")\n",
    "print(classification_report(y_test_rus,predictions_GPC5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC LR: 0.92\n",
      "Mean AUC WLR: 0.92\n",
      "Mean AUC GPC: 0.92\n"
     ]
    }
   ],
   "source": [
    "## getting AUC mean score for 5 fold cross validation on all data set for AUC\n",
    "scores_LR_AUC = cross_val_score(lg1, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean_LR_AUC=round(np.mean(scores_LR_AUC),2)\n",
    "print('Mean AUC LR:',mean_LR_AUC)\n",
    "\n",
    "scores_WLR_AUC = cross_val_score(lg4, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean_WLR_AUC=round(np.mean(scores_WLR_AUC),2)\n",
    "print('Mean AUC WLR:',mean_WLR_AUC)\n",
    "\n",
    "\n",
    "scores_GPC_AUC = cross_val_score(GPC5, X, y, cv=5, scoring= 'roc_auc')\n",
    "mean_GPC_AUC=round(np.mean(scores_WLR_AUC),2)\n",
    "print('Mean AUC GPC:',mean_GPC_AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall LR: 0.72\n",
      "Mean recall WLR: 0.89\n",
      "Mean recall GPC: 0.89\n"
     ]
    }
   ],
   "source": [
    "## getting AUC mean score for 5 fold cross validation on all data set for recall\n",
    "scores_LR_recall = cross_val_score(lg1, X, y, cv=5, scoring= 'recall')\n",
    "mean_LR_recall=round(np.mean(scores_LR_recall),2)\n",
    "print('Mean recall LR:',mean_LR_recall)\n",
    "\n",
    "scores_WLR_recall = cross_val_score(lg4, X, y, cv=5, scoring= 'recall')\n",
    "mean_WLR_recall=round(np.mean(scores_WLR_recall),2)\n",
    "print('Mean recall WLR:',mean_WLR_recall)\n",
    "\n",
    "\n",
    "scores_GPC_recall = cross_val_score(GPC5, X, y, cv=5, scoring= 'recall')\n",
    "mean_GPC_recall=round(np.mean(scores_WLR_recall),2)\n",
    "print('Mean recall GPC:',mean_GPC_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking the best model, and continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking with results, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindexing data so the description and title are next to each other,\n",
    "#  adding a colum to define if a job is Analytical or not\n",
    "# followed by our features of interest\n",
    "df_final=df_temp.merge(df_occupations,on=(\"Title\",\"O*NET-SOC Code\"),\n",
    "                                      how='left')\n",
    "df_final=df_final.reindex(columns=[\"O*NET-SOC Code\", \"Title\",\"Probability of Analytical\",\"Predicted Analytical\",\"Description\", 'Idea Generation and Reasoning Abilities',\n",
    "       'Critical Thinking', 'Active Learning', 'Complex Problem Solving',\n",
    "       'Information and Data Processing', 'Reasoning and Decision Making',\n",
    "       'Innovation', 'Analytical Thinking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining x of total data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to features (x) , and target (y)\n",
    "X_tot = df_final[['Idea Generation and Reasoning Abilities', 'Critical Thinking',\n",
    "       'Active Learning', 'Complex Problem Solving',\n",
    "       'Information and Data Processing', 'Reasoning and Decision Making',\n",
    "       'Innovation', 'Analytical Thinking']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Probability of Analytical']=GPC5.predict_proba(X_tot)[:,1]\n",
    "df_final['Predicted Analytical']=GPC5.predict(X_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Probability of Analytical']=df_final['Probability of Analytical'].apply(lambda x: round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_model_labeled.csv', header=True, na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    474\n",
       "1    399\n",
       "Name: Predicted Analytical, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Predicted Analytical'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of our probability prediction for two classes of 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.read_csv(\"df_model_labeled.csv\")\n",
    "z=df_final['Probability of Analytical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Probability of Analytical', ylabel='Count'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEHCAYAAABIsPrhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAee0lEQVR4nO3df1RUdf7H8eeAjPEjFcvVUitJTIzctDzUmrWbm20FEauFiuhSmdWqKXnIVutbbYratntKbckfqSiQbant2uaPNkyzBH9htk50tNoyf2QHTeGGM8J8/+hIUoEw3ZkBPq/HOZ4jA/d932/GuS/nzsznOrxerxcRETFSSLAbEBGR4FEIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYzK8hkJ2dTWFhISdPnuThhx9m+PDhjB07FrfbzcGDB0lLS2Po0KGsXr3an22IiEgdHP74nEBVVRWPPvoo27Zt47HHHuPLL78EYMSIEfzzn/+kb9++zJ8/n9tvv50rrriCUaNGsWTJEpxOZ/3NOhx2tyoiYoS6DvV+eSZQVVVFUlISKSkpAGzdupWysjJGjRrFF198QZcuXXC5XPTt2xen00lsbCx79+5tUG2v1+vTnz179vi8bXP+Y+LcJs5s6twmzuzL3PVp9bOP+D/B6XQyYMAASkpKAPjmm2+IjIxkyZIlTJgwgV27dlFdXV3zP/vw8HAsy2pQbZfL5VNPlZWVPm/bnJk4t4kzg5lzmzgz2Du3X0Lgh9q0acM111wDQEJCAh9//DEhId8/CbEsi6ioqAbViouL86kHl8vl87bNmYlzmzgzmDm3iTODvXMH5N1BvXv3ZsuWLQDs3r2bSy65hNjYWHbu3InH46G0tJSYmJhAtCIiImcIyDOBoUOHkpWVxdq1a+nVqxf9+vXjggsuYPLkyViWRVpa2llfFBYREfv5NQTGjRtX8/cXXnih1ve6dOnCsmXL/Ll7ERE5C31YTETEYAoBERGDKQRERAwWkBeGm4LzOnWmrMJta82wUAfnnhNma00RkUAyJgS8jlAezNtua80X0q6ytZ6ISKDpdJCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBvNrCGRnZ1NYWFjz9SuvvMLMmTMBOHjwIGlpaQwdOpTVq1f7sw0REamDX0KgqqqKrKws1q9fX3NbRUUFCxcurPk6JyeHzMxMcnNzycvLw+2294IvIiJydn4LgaSkJFJSUmpumzdvXq2vXS4Xffv2xel0Ehsby969e/3RioiI1MMvVxZzOp0MGDCAkpISAA4cOMDBgwcZPHgwGzZsAKC6uhqHwwFAeHg4lmU1qLbL5fKpp+hOXRu8j4byeDy4XPtsrWm3yspKn39nzZWJM4OZc5s4M9g7d0AuLzl79mzGjh3LwYMHa24LCfn+SYhlWURFRTWoVlxcnE89HD5WQUREhE/b1iUsLMznfgLF5XI1+R7tZuLMYObcJs4M9s4dkBDYuXMnU6ZM4fjx4xw7doyEhARiY2PZuXMn8fHxlJaWEhMTE4hWRETkDAEJgTVr1gBQVFTEhg0b+PWvf0337t2ZPHkylmWRlpaG0+kMRCsiInIGv4bAuHHjan2dkJBAQkICAF26dGHZsmX+3L2IiJyFPiwmImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBvNrCGRnZ1NYWMiBAwcYOXIkw4cP54knngDg4MGDpKWlMXToUFavXu3PNkREpA5+CYGqqiqysrJYv349APPnz+fBBx8kPz8fy7L44IMPyMnJITMzk9zcXPLy8nC73f5oRURE6uG3EEhKSiIlJQWA8ePH069fv5rvOZ1OXC4Xffv2xel0Ehsby969e/3RioiI1KOVP4o6nU4GDBhASUkJANHR0QC89dZbWJZFz549qa6uxuFwABAeHo5lWQ2q7XK5fOopulPXBu+joTweDy7XPltr2q2ystLn31lzZeLMYObcJs4M9s7tlxD4KevWrSM3N5ecnBwAQkK+fxJiWRZRUVENqhMXF+fT/g8fqyAiIsKnbesSFhbmcz+B4nK5mnyPdjNxZjBzbhNnBnvnDsi7g7Zt28bSpUt58cUXaw72sbGx7Ny5E4/HQ2lpKTExMYFoRUREzhCQZwLPPfccx44d4/777wcgMzOTBx54gMmTJ2NZFmlpaTidzkC0IiIiZ/BrCIwbNw6A3/zmNz/5/WXLlvlz9yIichb6sJiIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYzK8hkJ2dTWFhIeXl5dxzzz0MGzaMRYsWAXDw4EHS0tIYOnQoq1ev9mcbIiJSB7+EQFVVFVlZWaxfvx6A/Px8kpOTyc/PZ/PmzRw5coScnBwyMzPJzc0lLy8Pt9vtj1ZERKQerfxRtKqqiqSkJLp27QrArl27SE5OxuFw0K9fP0pKSnC5XDzxxBM4HA5iY2PZu3cvvXr18kc7fhPigLIK+8IrLNTBueeE2VZPRORs/BICTqeTAQMGUFJSAkB5eTmRkZEAhIeHU1FRQXV1NQ6Ho+Y2y7IaVNvlcvnUU3Snrg3eR0N5qqq5Z+Fm2+rN/8M17P90r231ACorK33+nTVXJs4MZs5t4sxg79x+CYEfioyMxLIsoqKisCyLzp07ExLy/Zmo099riLi4OJ96OHysgoiICJ+2rYvD4bC1ZlhYmM/z1cXlctles6kzcWYwc267Zj5R6cFT5bWho+/4+1m9nfd1QEIgPj6e4uJiEhMT2bp1KykpKcTGxrJz507i4+MpLS0lJiYmEK2IiPyIp8rLg3nbbav3QtpVttXyt4CEQFpaGg8//DCLFy9m4MCBdOzYkQceeIDJkydjWRZpaWk4nc5AtCIiImfwawiMGzeu5u8LFiyo9b0uXbqwbNkyf+5eRETOQh8WExExmEJARMRgCgEREYMpBEREDKYQEBExmEJARMRgCgEREYMpBEREDKYQEBExmEJARMRgDQqBoqKiWl+/8847fmlGREQCq961g959911KSkpYuXIlKSkpAHi9Xt58801uuOGGgDQoIiL+U28IdO/enSNHjuB0OunSpQterxeHw8GsWbMC1Z+IiPhRvSHQqVMnUlJSSE5O5sMPP+TkyZMAfPvttwFpTkRE/KtBS0mPHTsWt9tNp06dAGquFSwiIs1bg0Lg+PHjWvtfRKQFalAI9OrViw0bNhAbG1tzcfgLL7zQr42JiIj/NSgEXC5XrSvbOxwOcnNz/daUiIgERoNCYOnSpf7uQ0REgqBBITBo0CAcDgder5eqqirat2/PP/7xjwbv5OTJk4wfP57jx49z+eWXM2HCBB566CEsy2LQoEFkZGT4PICIiPiuQZ8YXrduHWvXrmXdunXMnTuXuLi4Ru1k06ZNdO/enYKCAr766isWL15McnIy+fn5bN68mSNHjvjUvIiI/DyNXjuoZ8+elJaWNmqbSy+9lKqqKrxeL5WVlRQVFZGQkFDzVtOSkpLGtiEiIjZo0Omg9PT0mtNBZWVl9O7du1E7CQsLY+PGjRQWFtKtWzcAIiMjAQgPD6eioqLBtc58gboxojt1xbIsn7ati9frtbWmx+PB5dpnWz2AyspKn39nzZWJM4OZc9s1c/sLLmryj+Uz2XlfNygEZsyYAXz3riCn08n555/fqJ0sXbqUjIwM7rzzTv7+97+Tk5ODZVlERUVhWRadO3ducK3Gnoo67fCxCiIiInzati4Oh8PWmmFhYT7PVxeXy2V7zabOxJnBzLntmrmswt3kH8tnsvO+btDpIIfDwcyZMxk9ejRTp07lf//7X6N2EhkZSVRUFADnn38+o0ePpri4GICtW7cSHx/fyLZFRMQODQqBxx57jLS0NF5//XVGjRrFlClTGrWTkSNHsnLlSkaMGMF//vMfUlJSWLVqFUOGDOHqq6+mY8eOPjUvIiI/T4NOB7ndbhISEgC49tprmTt3bqN20q5dO+bNm1frtgULFjSqhoiI2K9BIRAREcGKFSvo06cPO3bsqHlRV0REmrezhsDevXuZOXMmL774ImvWrKF169Y1LxSLiEjzVu9rAm+88QYTJ06kVatWPPLII4wdO5bPPvuMLVu2BKo/ERHxo3pDIDc3l+XLl9e8s6d3797k5eXx0ksvBaQ5ERHxr3pDwOl0/ui9s23atOGcc87xa1MiIhIY9YZA69at+eqrr2rd9sOvRUSk+ar3heHMzEzGjBnD9ddfT6dOnfj88895//33+b//+79A9SciIn5U7zOBXr16sXjxYi655BJOnDhBXFwcubm59OnTJ1D9iYiIH531LaJt27YlJSUlEL2IiEiANXopaRERaTkUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBmvQ5SV/Lq/Xy9NPP82ePXto3bo106dP57HHHsOyLAYNGkRGRkYg2hARCYgQB5RVuG2tGRbq4NxzwmytCQEKgQ0bNuB0OikoKOCdd95h9erVJCcnk5SUxOjRo0lMTKRDhw6BaEVEWoATlR48VV7aX3CRLQdbr9drQ1ffO1XtZWz+DltrvpB2la31TgtICGzduhWAjIwMYmJiOHToEMnJyTgcDvr160dJSQk33XRTIFoRkRbAU+XlwbztWJb1owtf+WLO8L42dNU8BSQEvvnmG1q3bs2iRYuYNWsWb731FjNnzgQgPDycioqKBtdyuVw+9RDdqSuWZfm0bV28Xq+tNT0eDy7XPtvqAVRWVvr8O2uuTJwZzJq7/QUXYVkW1dXVtjwG7X4s210Pah8f7LyvAxICbdq0qbkGwTXXXMO+ffuwLIuoqCgsy6Jz584NrhUXF+dTD4ePVdjyP4YzORwOW2uGhYX5PF9dXC6X7TWbOhNnBrPmLqtwExERYdszAbsfy3bXg9rHBzvv64C8O6h3795s2bIFgN27d3PFFVdQXFwMfHeqKD4+PhBtiIjIDwQkBG666Sa+/fZbUlNTKS0tZfjw4axatYohQ4Zw9dVX07Fjx0C0ISIiPxCQ00GtWrUiOzu71m0LFiwIxK5FpAk4/W4eu9j9bh6TBSQERMRsp9/NYxeT381jN31iWETEYAoBERGDKQRERAymEBARMZhCQETEYAoBERGDKQRERAymzwk0IXavQR7qwLaldk/z15rmIhIcCoEmxO41yOcM78voxVtsXcjKX2uai0hw6HSQiIjBFAIiIgZTCIiIGEwhICJiMIWAiIjBFAIiIgZTCIiIGEwhICJiMIWAiIjBAhoC7733HuPHj6e8vJx77rmHYcOGsWjRokC2ICIiZwhYCFRXVzN79mwA8vPzSU5OJj8/n82bN3PkyJFAtSEiImcIWAi8+uqr3HDDDQDs2rWLhIQEHA4H/fr1o6SkJFBtiIjIGQKygFx5eTlvv/02U6ZMYc+ePZSXlxMZGQlAeHg4FRUVDa7lcrl86iG6U1csy/Jp27p4vV5ba/qjXnV1ta01PR4PLtc+2+r5Q2Vlpc//Tpozu+Y+r1NnvI5QGzr6XmhoqF8eK3b9+27qj2Wo/diz8994QEJg/vz53HvvvTgcDgAiIyOxLIuoqCgsy6Jz584NrhUXF+dTD4ePVdi6miaAw+GwtaY/6oWEhNhaMywszOf7IFBcLleT79Ef7Jq7rMLNg3nbbejoe3OG9/XLY8WyLFvqNvXHMtR+7Nn5bzwgIbBjxw527NjByZMn+fzzzxkxYgTFxcUkJiaydetWUlJSAtGGGOBEpcfWayg0h+snnKj04Kny2ja31+u1oStpLgISAkuXLgVg//79zJo1i/T0dB5++GEWL17MwIED6dixYyDaEAN4qry2XkOhOVw/wVPl5cG87bb9r3jO8L42dCXNRUAvKtOlSxeef/55ABYsWBDIXYuIyE/Qh8VERAymy0tKo9h9HeTmcM7dbqfP4dtF5/Dl51AISKPYfR3k5nDO3W6nz+HbRefw5efQ6SAREYMpBEREDKYQEBExmEJARMRgemFYgsrudxvpnTIijaMQkKCy+91GeqeMSOPodJCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMEC8onh8vJyJk6cSGVlJdHR0UybNo0JEyZgWRaDBg0iIyMjEG2IiMgPBCQEXn75ZX73u98xePBgnnvuOQoKCkhOTiYpKYnRo0eTmJhIhw4dAtGKSKPYvbYRaH0jaVoCEgJDhw7F6XQCUFVVxfz581m9ejUOh4N+/fpRUlLCTTfdFIhWRBrF7rWNQOsbSdMSkBCIiooCYNeuXRQXF9OrVy8iIyMBCA8Pp6KiIhBtiIjIDwRsFdHt27czffp0XnjhBZ588kksyyIqKgrLsujcuXOD67hcLp/2H92pK5Zl+bRtXbxer601/VGvurq6yffYlGe2uz9/1Dxdz665NfPP54/focfjweXaB0BlZaXPx8IfCkgIfPrpp0yfPp2cnBw6dOhAfHw8xcXFJCYmsnXrVlJSUhpcKy4uzqceDh+rICIiwqdt6+JwOGyt6Y96ISEhTb7Hpjyz3f35o+bpepZl2VJXM/98/vgdhoWF1Rz/XC6Xz8fCHwpICMybN48TJ06QmZkJwMiRI1m+fDmLFy9m4MCBdOzYMRBtiIjIDwQkBLKzs390m14IFhEJPn1YTETEYAoBERGDKQRERAymEBARMZhCQETEYAoBERGDKQRERAymEBARMZhCQETEYAoBERGDKQRERAymEBARMZhCQETEYAoBERGDKQRERAymEBARMZhCQETEYAoBERGDKQRERAwWkGsM/5RTp04xadIkvvrqK3r37s3kyZOD1YqIiLGC9kxg3bp1XHbZZeTn53P8+HE++OCDYLUiImKsoIVASUkJCQkJAPzqV79ix44dwWpFRMRYQQuB8vJyIiMjAQgPD6eioiJYrYiIGMvh9Xq9wdjxtGnTuPXWW+nTpw//+te/OHr0KCNHjqx3G4fDEaDuRERalroO9UF7YTg+Pp7i4mL69OnDli1buPPOO8+6TZDySkSkxQra6aBbbrkFl8tFamoqoaGhXHnllcFqRUTEWEE7HSQiIsGnD4uJiBhMISAiYjCFgIiIwRQCIiIGa5EhcOrUKSZMmMDw4cOZMWNGre+tWrWKIUOGkJGRweHDh4PUof3qm3n+/PmkpqYydOhQPvzwwyB16B/1zQ3gdrv57W9/26I+jFjfzJs2bSI1NZXBgwfzzjvvBKlD/6hv7ry8PAYPHkx6ejqHDh0KUof+lZ2dTWFhYa3b7DietcgQqGtdIrfbTUFBAS+//DJ//OMfycnJCXKn9qlr5q+//ppNmzaxfPlynnnmGZ5//vkgd2qvs61BlZubS1lZWZC684+6Zq6qqmLOnDksXLiQhQsXsn///iB3aq/67uv8/HyWL1/O3XffzdKlS4PYpf2qqqrIyspi/fr1tW6363jWIkOgrnWJPvnkE3r06EGrVq246qqrWtT/iuuauV27djUH/lOnThEWFha0Hv2hvjWoysrK2L17N5dffnmw2vOLumb+9NNPiY6OZurUqUycOJH+/fsHs03b1Xdf9+zZk8rKSizLqlmOpqWoqqoiKSmJlJSUWrfbdTxrkSFQ17pEZ97ucDiorq4OWo92q2vmVq1a0a5dOyorK3n88ccZPXp0MNu0XX1rUM2dO5cHHnggWK35TV0zHzt2DJfLxVNPPcWjjz5KdnZ2MNu0XX33dWRkJImJiWRnZ3PbbbcFq0W/cDqdDBgw4Ee323U8a5EhEBkZiWVZAFiWxbnnnvuj271eL61aBW3VDNvVNTNARUUF999/P6mpqS3uk9l1zb1v3z48Hg89e/YMZnt+UdfMbdu2JS4ujjZt2tCjRw+OHDkSzDZtV9fcH330EZ9++inr16+noKCAqVOnBrPNgLHreNYiQ+D0ukQAW7ZsoXfv3gDExMTw0Ucf4fF42L59O5dddlkw27RVXTMDTJgwgWHDhpGYmBis9vymrrk3b96My+UiPT0dl8vFI488Esw2bVXXzBdddBFffvkl5eXl7N+/n3bt2gWxS/vVNXdkZCQRERGEhYXRtm1bvv3222C2GTB2Hc9a5LIRbrebrKwsDh48yGWXXUZiYiIff/wxI0aMYMWKFRQUFBAaGsqzzz5L586dg92uLeqauUePHowZM4b4+HgAunXrxlNPPRXkbu1T3319Wnp6Ojk5OS3mXHF9M69Zs4Z58+YREhLCk08+2aJeD6lv7pycHAoLC3E4HDz00ENce+21wW7XdrNnzyY+Pp7IyEhbj2ctMgRERKRhWuTpIBERaRiFgIiIwRQCIiIGUwiIiBhMISAiYjCFgARdUVER/fv3Jz09nfT0dO68807Wrl3boG1XrFjB7NmzG/SzkydPpqioqNZtLpeLefPmsX//ftLT0wGYOHEiAG+99ZbP6w6dOHGCu+66q6bWmQYPHuzzp3l/aobTtm3bxr59+zhy5AjTpk1rVN0bb7zRp36k+Ws5H5mVZm3AgAE1K0N+8803DBkyhJtvvtnv+42LiyMuLq7WYmt/+9vfAFiyZAk9e/akffv2ja5bWlpK165defbZZ2vdvmfPHmJiYti8eTNutxun0/nzBjjDq6++SkpKCpdeeilTpkyxra60bHomIE3OiRMnCA8PB2DgwIGMGjWKnJwcPvzwQ4YNG8aIESOYNGkSbrcbgOLiYkaOHElqaiolJSUALFy4kFGjRpGamsqTTz5ZU3vx4sWMGjWKe++9l6+//pqioiImT55ca/833ngjGzdurPmk8V/+8hdWrVoFfLdEQWZmZq2f37hxI3fddRfDhg1j+vTpAPz5z39my5YtLFq0qNbPrlixgptvvpn+/fuzZs0a4LtnQvfddx9jxowhMTGxZgnoumYASE1N5cCBA8B3YTVv3jw2bdrE9OnT+e9//1vzrCYvL4/f//733HHHHaxcuRKPx0NWVhZ33303KSkprFy5svF3kLQoeiYgTcKmTZtIT0/H4XAQHh7O008/DcChQ4d4/fXXiYqKYsiQITzzzDN069aN559/nuXLlxMZGUm7du2YPXs2X3zxBRMnTmT58uW43W6WLFlCdXU1t9xyS80aK9deey0jR45k1apVzJ8/v87TINdffz1xcXFkZ2fjdruZNm0ad9xxB6+//jp33HFHzc95vV6efvppli9fTnR0NI888ghvv/02f/rTn1i5ciUZGRk1P+t2u9m0aRNZWVlceOGFTJ8+ndtvvx34bsnv1157jZKSEubMmcN1111X5wwAKSkprF69mvvuu481a9bw4osv8sknn5CSkkLbtm1rahYUFLBixQqqqqqYPXs2hw4don///iQnJ3PgwAHGjRv3o9UpxSwKAWkSzjwddKYOHToQFRUFwNGjR+nWrRsAV111FWvXruXKK6+kb9++AHTt2pWjR48SGhpKdXU1kyZNIjw8HMuyOHXqVM12AFdccQX//ve/G9RbTEwMlZWVHD58mOLiYiZNmlTzvbKyMtq1a0d0dHRN/b179/LLX/7yR3UKCws5efJkzcqmLpeLffv2ARAbG4vD4eCCCy7A7XbXOwPAbbfdRkZGBgMHDqRTp060adPmR/vbv38/PXr0qDnllJWVRXl5Odu2beO9997jnHPOqVVTzKQQkCYtJOT7M5Zt27bls88+45JLLmHbtm1cfPHFAOzevRv4bj39888/n48++oh3332XgoICysrKWLt2LadXRzl9fYEdO3bQvXv3s+7/9HbJycnMmDGDa665htDQ0JrvR0dHc/ToUY4ePUp0dDTbtm2r89nFypUr+etf/1oTWkuWLOGVV17hxhtvxOFw1PrZ+mYAOPfcc7n44ouZM2dOzTMTh8NR62e6du3K3r178Xg8eL1eHnzwQQYMGED79u2ZOHEi77//Pjt37jzr70BaNoWANBtPPPFEzfn7X/ziF8ycOZM333yT48ePM3LkSNxuN48//jgXX3wxoaGhDBkyhPDwcLp06VKzrHJxcTFvvPEG4eHhzJo1i9LS0jr3d+WVV5KZmUleXh633nor06dP57XXXqv1MyEhIUydOpUxY8bg9XqJi4tj0KBBbN26tdbPff3113zyySf06dOn5rakpCRuv/12rrvuuh/tu74ZThs8eHDNaxbw3SqbM2bMqFlK+bzzzmP48OEMHz4cgBEjRtCzZ08yMzMpKirivPPO49SpUy3quhrSeFpATqQBjh07xoQJE1i8eHGwW6mxceNGtm3b9qMXqkUaQ+8OEjmLoqIi0tPTGT9+fLBbqfHSSy8xd+5c/vCHPwS7FWnm9ExARMRgeiYgImIwhYCIiMEUAiIiBlMIiIgYTCEgImIwhYCIiMH+H2Lhzg5dEaPUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.set_style(\"whitegrid\", {'axes.linewidth': 2, 'axes.edgecolor':'black'})\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.histplot(z,kde=False,bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this figure igure shows probability distribution of model over whole dataset, as we see distribution of probabilities are not highly concentrated around border threshold which is 0.5 in this case, and reflecting the fact that model is strong in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
